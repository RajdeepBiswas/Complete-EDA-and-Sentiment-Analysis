{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "gather": {
     "logged": 1612451213316
    }
   },
   "source": [
    "### Process Followed\n",
    "#### 1. Get the restaurant reviews\n",
    "#### 2. Classify negative < 3 positive >=3. and put as a target column 'Actual_Sentiment'\n",
    "#### 3. Clean the data defining a function 'function_clean'\n",
    "#### 4. Split into train test dataset\n",
    "#### 5. Tokenize\n",
    "#### 6. Lemmatize\n",
    "#### 7. Remove Stopwords\n",
    "#### 8. Vectorizing the text using TF_IDF\n",
    "#### 9. Balance the dataset (I used SMOTE from imblearn)\n",
    "#### 10. Quick test fitting a logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1612451213495
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1612451213767
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Dataset, Datastore\n",
    "subscription_id = '<subscription_id>'\n",
    "resource_group = '<resource_group>'\n",
    "workspace_name = '<workspace_name>'\n",
    "\n",
    "workspace = Workspace(subscription_id, resource_group, workspace_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gather": {
     "logged": 1612451253971
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credentials are not provided to access data from the source. Please sign in using identity with required permission granted.\n",
      "Interactive sign-in timeout: 120 sec.\n",
      "To change the sign-in tenant, restart the session with tenant ID set to environment variable \"AZUREML_DATA_ACCESS_TENANT_ID\" before sign in.\n",
      "To always use device code for interactive sign-in, set environment variable \"AZUREML_DATA_ACCESS_USE_DEVICE_CODE\" to \"true\".\n",
      "To configure timeout, set environment variable \"AZUREML_DATA_ACCESS_INTERACT_TIMEOUT\" to the number of seconds.\n",
      "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code AKKFACYAL to authenticate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "InteractiveBrowserCredential.get_token failed: Failed to open a browser\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xQY8N_XvtGbearJ5X4QryQ</td>\n",
       "      <td>-MhfebM0QIsKt87iDN-FNw</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-04-15</td>\n",
       "      <td>As someone who has worked with many museums, I...</td>\n",
       "      <td>OwjRMXRC0KyPrIlcjaXeFQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UmFMZ8PyXZTY2QcwzsfQYA</td>\n",
       "      <td>lbrU8StCq3yDfr-QMnGrmQ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-12-07</td>\n",
       "      <td>I am actually horrified this place is still in...</td>\n",
       "      <td>nIJD_7ZXHq-FX8byPMOkMQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LG2ZaYiOgpr2DK_90pYjNw</td>\n",
       "      <td>HQl28KMwrEKHqhFrrDqVNQ</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-12-05</td>\n",
       "      <td>I love Deagan's. I do. I really do. The atmosp...</td>\n",
       "      <td>V34qejxNsCbcgD8C0HVk-Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id             business_id  stars  useful  funny  cool  \\\n",
       "0  xQY8N_XvtGbearJ5X4QryQ  -MhfebM0QIsKt87iDN-FNw      2       5      0     0   \n",
       "1  UmFMZ8PyXZTY2QcwzsfQYA  lbrU8StCq3yDfr-QMnGrmQ      1       1      1     0   \n",
       "2  LG2ZaYiOgpr2DK_90pYjNw  HQl28KMwrEKHqhFrrDqVNQ      5       1      0     0   \n",
       "\n",
       "        date                                               text  \\\n",
       "0 2015-04-15  As someone who has worked with many museums, I...   \n",
       "1 2013-12-07  I am actually horrified this place is still in...   \n",
       "2 2015-12-05  I love Deagan's. I do. I really do. The atmosp...   \n",
       "\n",
       "                  user_id  \n",
       "0  OwjRMXRC0KyPrIlcjaXeFQ  \n",
       "1  nIJD_7ZXHq-FX8byPMOkMQ  \n",
       "2  V34qejxNsCbcgD8C0HVk-Q  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the yelp Dataset from adlsgen2\n",
    "dataset_yelp_review = Dataset.get_by_name(workspace, 'yelp_review')\n",
    "dataset_yelp_review.take(3).to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1612451262006
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Conver to Pandas Dataframe\n",
    "df_yelp_review = dataset_yelp_review.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gather": {
     "logged": 1612451262295
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>Actual_Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xQY8N_XvtGbearJ5X4QryQ</td>\n",
       "      <td>-MhfebM0QIsKt87iDN-FNw</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-04-15</td>\n",
       "      <td>As someone who has worked with many museums, I...</td>\n",
       "      <td>OwjRMXRC0KyPrIlcjaXeFQ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UmFMZ8PyXZTY2QcwzsfQYA</td>\n",
       "      <td>lbrU8StCq3yDfr-QMnGrmQ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-12-07</td>\n",
       "      <td>I am actually horrified this place is still in...</td>\n",
       "      <td>nIJD_7ZXHq-FX8byPMOkMQ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LG2ZaYiOgpr2DK_90pYjNw</td>\n",
       "      <td>HQl28KMwrEKHqhFrrDqVNQ</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-12-05</td>\n",
       "      <td>I love Deagan's. I do. I really do. The atmosp...</td>\n",
       "      <td>V34qejxNsCbcgD8C0HVk-Q</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id             business_id  stars  useful  funny  cool  \\\n",
       "0  xQY8N_XvtGbearJ5X4QryQ  -MhfebM0QIsKt87iDN-FNw      2       5      0     0   \n",
       "1  UmFMZ8PyXZTY2QcwzsfQYA  lbrU8StCq3yDfr-QMnGrmQ      1       1      1     0   \n",
       "2  LG2ZaYiOgpr2DK_90pYjNw  HQl28KMwrEKHqhFrrDqVNQ      5       1      0     0   \n",
       "\n",
       "         date                                               text  \\\n",
       "0  2015-04-15  As someone who has worked with many museums, I...   \n",
       "1  2013-12-07  I am actually horrified this place is still in...   \n",
       "2  2015-12-05  I love Deagan's. I do. I really do. The atmosp...   \n",
       "\n",
       "                  user_id  Actual_Sentiment  \n",
       "0  OwjRMXRC0KyPrIlcjaXeFQ                 0  \n",
       "1  nIJD_7ZXHq-FX8byPMOkMQ                 0  \n",
       "2  V34qejxNsCbcgD8C0HVk-Q                 1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new column \"Actual_Sentiment\" that stored 0's or 1's.\n",
    "# 0 being Negative, 1 being Positive\n",
    "import numpy as np\n",
    "df_yelp_review[\"Actual_Sentiment\"] = np.where(df_yelp_review[\"stars\"] >= 3, 1, 0)\n",
    "df_yelp_review.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gather": {
     "logged": 1612451262513
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Actual_Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As someone who has worked with many museums, I...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am actually horrified this place is still in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I love Deagan's. I do. I really do. The atmosp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dismal, lukewarm, defrosted-tasting \"TexMex\" g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh happy day, finally have a Canes near my cas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  Actual_Sentiment\n",
       "0  As someone who has worked with many museums, I...                 0\n",
       "1  I am actually horrified this place is still in...                 0\n",
       "2  I love Deagan's. I do. I really do. The atmosp...                 1\n",
       "3  Dismal, lukewarm, defrosted-tasting \"TexMex\" g...                 0\n",
       "4  Oh happy day, finally have a Canes near my cas...                 1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We only need the text (review) and Actual_Sentiment columns for sentiment prediction\n",
    "df_ml_yelp_review = df_yelp_review[['text','Actual_Sentiment']]\n",
    "df_ml_yelp_review.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gather": {
     "logged": 1612451262683
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1009534, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ml_yelp_review.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1612451262901
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Build punctuation dictionary\n",
    "import unicodedata\n",
    "import sys\n",
    "\n",
    "# Create a dictionary of punctuation characters\n",
    "punctuation = dict.fromkeys(i for i in range(sys.maxunicode)\n",
    "                            if unicodedata.category(chr(i)).startswith('P'))\n",
    "# Add the backtick/ Grave accent character\n",
    "punctuation.update({96:None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "gather": {
     "logged": 1612451263034
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ab5z8dY\n"
     ]
    }
   ],
   "source": [
    "#Cant use \\W as it strips the spaces\n",
    "s = 'ab5z8d *$&Y@#'\n",
    "#regx = re.compile('\\W')\n",
    "#result = regx.findall(s)\n",
    "s = re.sub('\\W', \"\", s)\n",
    "print (s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1612451263110
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Let us clean up and make the data ready\n",
    "import re \n",
    "def function_clean(text):\n",
    "    #convert into lowercase\n",
    "    text = text.lower()\n",
    "    #removing the URL Http\n",
    "    text = re.sub(r\"http\\S+\", \"\", text) \n",
    "    # Removal of mentions\n",
    "    #text = re.sub(\"@[^\\s]*\", \"\", text)\n",
    "    # Removal of hashtags\n",
    "    #text = re.sub(\"#[^\\s]*\", \"\", text)\n",
    "    # Removal of numbers\n",
    "    text = re.sub('[0-9]*[+-:]*[0-9]+', '', text)\n",
    "    text = re.sub(\"'s\", \"\", text)   \n",
    "    #remove all punctuation from the text.\n",
    "    text = str(text.translate(punctuation))\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1612451312977
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# applying the cleaning function to text column\n",
    "df_ml_yelp_review['text'] = df_ml_yelp_review['text'].apply(lambda text: function_clean(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "gather": {
     "logged": 1612451313084
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Actual_Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>as someone who has worked with many museums i ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i am actually horrified this place is still in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i love deagan i do i really do the atmosphere ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dismal lukewarm defrostedtasting texmex glop\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oh happy day finally have a canes near my casa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  Actual_Sentiment\n",
       "0  as someone who has worked with many museums i ...                 0\n",
       "1  i am actually horrified this place is still in...                 0\n",
       "2  i love deagan i do i really do the atmosphere ...                 1\n",
       "3  dismal lukewarm defrostedtasting texmex glop\\n...                 0\n",
       "4  oh happy day finally have a canes near my casa...                 1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ml_yelp_review.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1612451313275
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Splitting the data to train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = df_ml_yelp_review[\"text\"]\n",
    "y = df_ml_yelp_review[\"Actual_Sentiment\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "gather": {
     "logged": 1612451313439
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    771908\n",
       "0    237626\n",
       "Name: Actual_Sentiment, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "gather": {
     "logged": 1612451313603
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((807627,), (201907,), (807627,), (201907,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1612451313675
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Now it is time to preprocess the reviews because all these modifications will directly affect the classifier’s performance.\n",
    "# As we are going to use words as features so we can use some text formatting techniques which will help us in feature extraction\n",
    "#  including removing punctuation marks/digits ,and also stop-words. In addition, the implementation of lemmatization words using NLTK\n",
    "#   can be workable to maximize the performance. Tokenization is the last step to break reviews up into words and other meaningful tokens.\n",
    "import string\n",
    "#pip install nltk\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "ENGLISH_STOP_WORDS = stopwords.words('english')\n",
    "\n",
    "def my_tokenizer(sentence):\n",
    "\n",
    "    listofwords = sentence.strip().split()          # to remove any space from beginning and the end of text\n",
    "    tokenized_words = []    \n",
    "    for word in listofwords:\n",
    "        if not word in ENGLISH_STOP_WORDS:\n",
    "            lemm_word = WordNetLemmatizer().lemmatize(word)\n",
    "            if len(lemm_word)>0:\n",
    "                tokenized_words.append(lemm_word)\n",
    "    return(tokenized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1612451313755
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1612452523440
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Vectorizing the text using TF_IDF\n",
    "\n",
    "#By implementing the sklearn library, we can use TF_IDF vectorizing to find \n",
    "#the weighted words that occur more frequently in the document that leads to\n",
    "# creation of the bag of words model. So our features will be the words or sequence of\n",
    "# words of these reviews. We are going to explore different models with\n",
    "# the combinations of n_grams (unigrams,bigrams,trigrams).\n",
    "#min_df float or int, default=1\n",
    "#When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold.\n",
    "# This value is also called cut-off in the literature. If float in range of [0.0, 1.0], \n",
    "# the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.\n",
    "\n",
    "#ngram_rangetuple (min_n, max_n), default=(1, 1)\n",
    "#The lower and upper boundary of the range of n-values for different n-grams to be extracted. All values of n such \n",
    "#that min_n <= n <= max_n will be used. For example an ngram_range of (1, 1) means only unigrams, (1, 2) means\n",
    "# unigrams and bigrams, and (2, 2) means only bigrams. Only applies if analyzer is not callable.\n",
    "\n",
    "#tokenizer callable, default=None\n",
    "#Override the string tokenization step while preserving the preprocessing and n-grams generation steps. \n",
    "#Only applies if analyzer == 'word'.\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect_1 = TfidfVectorizer(min_df=100,tokenizer=my_tokenizer, stop_words={'english'}, ngram_range=(1,3)).fit(X_train)\n",
    "X_train1 = vect_1.transform(X_train)\n",
    "X_test1 = vect_1.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "gather": {
     "logged": 1612452524157
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20184</th>\n",
       "      <td>food</td>\n",
       "      <td>16256.512063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42479</th>\n",
       "      <td>place</td>\n",
       "      <td>15897.399134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25242</th>\n",
       "      <td>great</td>\n",
       "      <td>15711.074147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24084</th>\n",
       "      <td>good</td>\n",
       "      <td>15048.560139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50479</th>\n",
       "      <td>service</td>\n",
       "      <td>13057.707995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57633</th>\n",
       "      <td>time</td>\n",
       "      <td>12605.651439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22530</th>\n",
       "      <td>get</td>\n",
       "      <td>10409.801529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31651</th>\n",
       "      <td>like</td>\n",
       "      <td>10291.548429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39072</th>\n",
       "      <td>one</td>\n",
       "      <td>10017.469266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3865</th>\n",
       "      <td>back</td>\n",
       "      <td>9919.693044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23494</th>\n",
       "      <td>go</td>\n",
       "      <td>9370.418949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64361</th>\n",
       "      <td>would</td>\n",
       "      <td>9273.538127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45834</th>\n",
       "      <td>really</td>\n",
       "      <td>8800.083382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33484</th>\n",
       "      <td>love</td>\n",
       "      <td>8045.611761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5246</th>\n",
       "      <td>best</td>\n",
       "      <td>7928.871009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37840</th>\n",
       "      <td>nice</td>\n",
       "      <td>7731.507112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53590</th>\n",
       "      <td>staff</td>\n",
       "      <td>7597.878646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>always</td>\n",
       "      <td>7589.642820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59946</th>\n",
       "      <td>u</td>\n",
       "      <td>7585.785402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>also</td>\n",
       "      <td>7434.197916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word         count\n",
       "20184     food  16256.512063\n",
       "42479    place  15897.399134\n",
       "25242    great  15711.074147\n",
       "24084     good  15048.560139\n",
       "50479  service  13057.707995\n",
       "57633     time  12605.651439\n",
       "22530      get  10409.801529\n",
       "31651     like  10291.548429\n",
       "39072      one  10017.469266\n",
       "3865      back   9919.693044\n",
       "23494       go   9370.418949\n",
       "64361    would   9273.538127\n",
       "45834   really   8800.083382\n",
       "33484     love   8045.611761\n",
       "5246      best   7928.871009\n",
       "37840     nice   7731.507112\n",
       "53590    staff   7597.878646\n",
       "1516    always   7589.642820\n",
       "59946        u   7585.785402\n",
       "1174      also   7434.197916"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counting most repetitive words \n",
    "word_counts = np.array(np.sum(X_train1, axis=0)).reshape((-1,))\n",
    "words = np.array(vect_1.get_feature_names())\n",
    "words_df = pd.DataFrame({\"word\":words, \"count\":word_counts})\n",
    "words_df.sort_values(by=\"count\",ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1612452524632
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1612452524922
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#pip install -U imbalanced-learn\n",
    "#pip install imblearn\n",
    "#pip install delayed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1612454957987
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#The only challenge that we’ve faced was about balancing the train dataset in terms of having the equal \n",
    "#numbers of positive and negative reviews for our two classes. \n",
    "#So we are using SMOTE to balanace our target(class) column.\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#SMOTE the training data\n",
    "sm = SMOTE(random_state=1)\n",
    "X_bal, y_bal = sm.fit_resample(X_train1, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "gather": {
     "logged": 1612457768306
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1234728, 65450)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "gather": {
     "logged": 1612457862221
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_bal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "gather": {
     "logged": 1612454958403
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    617364\n",
       "0    617364\n",
       "Name: Actual_Sentiment, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_bal.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1612457389771
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "df_y_bal = pd.DataFrame(y_bal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wanted to show here the real life problem when we run out of memeory:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "gather": {
     "logged": 1612457640062
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 602. GiB for an array with shape (1234728, 65450) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-e2e3b0232611>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_X_bal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_bal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m             \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Output array must be C or F contiguous'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1183\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 602. GiB for an array with shape (1234728, 65450) and data type float64"
     ]
    }
   ],
   "source": [
    "#cannot happen\n",
    "df_X_bal = pd.DataFrame(X_bal.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "gather": {
     "logged": 1612457677553
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Method register_pandas_dataframe: This is an experimental method, and may change at any time.<br/>For more information, see https://aka.ms/azuremlexperimental.\n",
      "Method register_pandas_dataframe: This is an experimental method, and may change at any time.<br/>For more information, see https://aka.ms/azuremlexperimental.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating arguments.\n",
      "Arguments validated.\n",
      "Successfully obtained datastore reference and path.\n",
      "Uploading file to X_bal/19df57e1-2d75-41b7-97f9-e43618be3dbc/\n",
      "Successfully uploaded file to datastore.\n",
      "Creating and registering a new dataset.\n",
      "Successfully created and registered a new dataset.\n",
      "Validating arguments.\n",
      "Arguments validated.\n",
      "Successfully obtained datastore reference and path.\n",
      "Uploading file to y_bal/68378b0d-ba32-4e31-b1d9-5a56df46245e/\n",
      "Successfully uploaded file to datastore.\n",
      "Creating and registering a new dataset.\n",
      "Successfully created and registered a new dataset.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('workspaceblobstore', 'y_bal/68378b0d-ba32-4e31-b1d9-5a56df46245e/')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\",\n",
       "    \"ReadParquetFile\",\n",
       "    \"DropColumns\"\n",
       "  ],\n",
       "  \"registration\": {\n",
       "    \"id\": \"8d065503-9942-4107-89de-80ed849257f8\",\n",
       "    \"name\": \"y_bal\",\n",
       "    \"version\": 1,\n",
       "    \"workspace\": \"Workspace.create(name='Houston-techsummit-workspace', subscription_id='7ca151c5-e4f7-4663-9583-834f4e0e6ed4', resource_group='calcutta_demos')\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.data.datapath import DataPath\n",
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "#Usage: register_pandas_dataframe(dataframe, target, name, description=None, tags=None, show_progress=True)\n",
    "\n",
    "\n",
    "datastore_default = workspace.get_default_datastore()\n",
    "data_path_X_bal = DataPath(datastore=datastore_default, path_on_datastore='X_bal')\n",
    "TabularDatasetFactory.register_pandas_dataframe(df_X_bal, data_path_X_bal, 'X_bal', show_progress=True)\n",
    "data_path_y_bal = DataPath(datastore=datastore_default, path_on_datastore='y_bal')\n",
    "TabularDatasetFactory.register_pandas_dataframe(df_y_bal, data_path_y_bal, 'y_bal', show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "X_train1 = vect_1.transform(X_train)\n",
    "X_test1 = vect_1.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "gather": {
     "logged": 1612455018728
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training set: 0.935764901371549\n",
      "Score on test set: 0.9266840674171772\n"
     ]
    }
   ],
   "source": [
    "# fitting a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Fitting Logistic regression to the training set\n",
    "logreg = LogisticRegression(solver='lbfgs',multi_class='auto',random_state=1)\n",
    "logreg.fit(X_bal, y_bal)\n",
    "\n",
    "# Predicting the test set results\n",
    "y_pred_logreg = logreg.predict(X_test1)\n",
    "\n",
    "# Training score\n",
    "print(f\"Score on training set: {logreg.score(X_train1,y_train)}\")\n",
    "print(f\"Score on test set: {logreg.score(X_test1,y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "gather": {
     "logged": 1612455019272
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Confusion Matrix\n",
      "The Classification report\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True 0</th>\n",
       "      <td>42496</td>\n",
       "      <td>4867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True 1</th>\n",
       "      <td>9936</td>\n",
       "      <td>144608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Predicted 0  Predicted 1\n",
       "True 0        42496         4867\n",
       "True 1         9936       144608"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.810497</td>\n",
       "      <td>0.897240</td>\n",
       "      <td>0.851666</td>\n",
       "      <td>47363.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.967439</td>\n",
       "      <td>0.935708</td>\n",
       "      <td>0.951309</td>\n",
       "      <td>154544.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.926684</td>\n",
       "      <td>0.926684</td>\n",
       "      <td>0.926684</td>\n",
       "      <td>0.926684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.888968</td>\n",
       "      <td>0.916474</td>\n",
       "      <td>0.901487</td>\n",
       "      <td>201907.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.930624</td>\n",
       "      <td>0.926684</td>\n",
       "      <td>0.927935</td>\n",
       "      <td>201907.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score        support\n",
       "0              0.810497  0.897240  0.851666   47363.000000\n",
       "1              0.967439  0.935708  0.951309  154544.000000\n",
       "accuracy       0.926684  0.926684  0.926684       0.926684\n",
       "macro avg      0.888968  0.916474  0.901487  201907.000000\n",
       "weighted avg   0.930624  0.926684  0.927935  201907.000000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print('The Confusion Matrix')\n",
    "con_mat_lr = confusion_matrix(y_test, y_pred_logreg)\n",
    "df_cm_lr = pd.DataFrame(con_mat_lr, columns = ['Predicted 0','Predicted 1'], index = ['True 0','True 1'])\n",
    "display(df_cm_lr)\n",
    "print('The Classification report')\n",
    "report = classification_report(y_test, y_pred_logreg, output_dict=True)\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "df_report"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
